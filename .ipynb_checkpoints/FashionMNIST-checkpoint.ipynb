{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST\n",
    "Use this notebook as a skeleton for developing your own network to solve this classification problem!\n",
    "Feel free to experiment (as a matter of fact, its encouraged) with what you've learned so far here. Don't be afraid to ask questions and use different architectures.\n",
    "Be conscious of what you don't know so that you know what to ask/look for.\n",
    "\n",
    "No GPU required!\n",
    "\n",
    "The basic 7 steps for building models in general are listed so:\n",
    " 1. Load Dataset\n",
    " 2. Make Dataset Iterable\n",
    " 3. Create Model Class\n",
    " 4. Instantiate Model Class\n",
    " 5. Instantiate Loss Class\n",
    " 6. Instantiate Optimizer Class\n",
    " 7. Train Model\n",
    "\n",
    "I have handled steps 1 and 2 for you. Please handle the rest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the below cells until 'stop' to get your data processed and loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "SOS_token = '<SOS>'\n",
    "EOS_token = '<EOS>'\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0        30        43   \n",
       "3       0    ...            3         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         1         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "STEP 1: LOAD DATASET\n",
    "'''\n",
    "test_df = pd.read_csv('fashionmnist/fashion-mnist_test.csv')\n",
    "test_labels_df = test_df['label']\n",
    "test_pixels_df = test_df.drop('label', axis=1)\n",
    "\n",
    "'''\n",
    "If you're curious about how I did this see the below cells. If not just skip to STEP 1.5\n",
    "\n",
    "Pandas is a library for dataprocessing. You might run into dask.DataFrame at some point if you continue with ML.\n",
    "dask.DataFrame is built ontop of Pandas with the purpose of concurrency and parallelized computing...basically when\n",
    "working with datasets so large that you require multiple machines to handle it. This is part of the data pipeline!\n",
    "'''\n",
    "\n",
    "# This reads the csv file into a pandas dataframe\n",
    "train_df = pd.read_csv('fashionmnist/fashion-mnist_train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       5       0   \n",
       "3       0       0       0       1       2       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel10    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0        0    ...            0         0         0         0         0   \n",
       "1        0    ...            0         0         0         0         0   \n",
       "2        0    ...            0         0         0        30        43   \n",
       "3        0    ...            3         0         0         0         0   \n",
       "4        0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         1         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a new dataframe without the 'label' column here so we only get the pixel data\n",
    "# The original dataframe train_df is unmodified\n",
    "train_pixels_df = train_df.drop('label', axis=1)\n",
    "train_pixels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 9, 6, ..., 8, 8, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we grab only the labels. Keep in mind that we do not change the order of either the pixel values nor the labels\n",
    "# so that they stay consistent\n",
    "train_labels_df = train_df['label']\n",
    "train_labels_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 1.5: defining and instantiating Dataset subclass \n",
    "'''\n",
    "\n",
    "'''\n",
    "This is our custom Dataset class. Remember from 1st meeting that we need this to pipeline our data into training our model.\n",
    "\n",
    "The pipeline is important!!! At larger scale, machine learning can get bottlenecked at disk reads (in image classification for example)\n",
    "so understanding the various stages is important. We don't have to worry about that kind of stuff now since we're just creating small\n",
    "project models as opposed to complex production models.\n",
    "\n",
    "NOTE: this is not the only way to create a dataset. An alternative is to simply pass in a dataframe that contains both pixel and label data.\n",
    "Then we can index the label and pixel data inside of __getitem__ as opposed to separating labels and pixel data before hand like I did.\n",
    "'''\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, dataframe, labels):\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.df = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # I'm using .loc to access the row of the dataframe by index\n",
    "        # HINT You don't need to do this but try normalizing your image vector before making it a torch Tensor.\n",
    "        # BONUS train your model with and without normalization and see what happens\n",
    "        img = torch.Tensor(self.df.loc[index].values)\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    \n",
    "'''\n",
    "This class is for providing image data as (1, 28, 28) tensor as opposed to a (784) tensor. You\n",
    "use these for conv2d layers which are powerful for image recognition!\n",
    "'''\n",
    "class Fashion2DDataset(Dataset):\n",
    "    def __init__(self, dataframe, labels):\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.df = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # I'm using .loc to access the row of the dataframe by index\n",
    "        a = self.df.loc[index].values\n",
    "        a = np.split(a, 28)\n",
    "        a = np.array([a])\n",
    "        img = torch.Tensor(a)\n",
    "        \n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "train_dataset = FashionDataset(train_pixels_df, train_labels_df)\n",
    "test_dataset = FashionDataset(test_pixels_df, test_labels_df)\n",
    "\n",
    "'''\n",
    "Batch_size will determine how many data samples to go through before \n",
    "updating the weights of our model with SGD (stochastic gradient descent)\n",
    "\n",
    "Currently at 100 but feel free to change this to whatever you want. You can consider\n",
    "batch size a hyper parameter!\n",
    "'''\n",
    "batch_size = 100\n",
    "\n",
    "# shuffle is true so that we train our data on all labels simultaneously. The data is already shuffled in \n",
    "# this case(You can verify this by looking through the training labels by running train_labels in its own cell)\n",
    "# If this wasn't the case, and we had shuffle=False, we might end up training the model on label = 0 and \n",
    "# then ending with label = 9. This would cause the model to 'forget' what label = 0 looked like\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# shuffle=False because theres no reason to do so with testing\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop\n",
    "\n",
    "Below this block is your responsibility! Best of luck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221616\n"
     ]
    }
   ],
   "source": [
    "# STEP 2.5: CLEANING DATA\n",
    "movie_text = open('moviedialogues/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "conv_lines = open('moviedialogues/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "\n",
    "lineToText = {}  # mapping of line number to text\n",
    "# inputToOutput = {}\n",
    "inputs = []\n",
    "outputs = []\n",
    "for line in movie_text:\n",
    "    things = line.split(\"+++$+++\")\n",
    "#     print(things)\n",
    "    if (len(things) == 5):  \n",
    "#         key = re.sub(\"[^0-9]\", \"\", things[0])\n",
    "        val = things[4].translate(str.maketrans('', '', string.punctuation))\n",
    "#         lineToText[int(key)] = val\n",
    "        lineToText[things[0].replace(\" \", \"\")] = val\n",
    "\n",
    "        \n",
    "# print(lineToText[295])\n",
    "\n",
    "\n",
    "for conversation in conv_lines:\n",
    "    things = conversation.split(\"+++$+++\")\n",
    "    if (len(things) == 4):\n",
    "        convo = things[3]\n",
    "        convo = [x.strip() for x in convo.split(',')]\n",
    "        convo[0] = convo[0].replace(\"[\", \"\")\n",
    "        convo[len(convo) - 1] = convo[len(convo) - 1].replace(\"]\", \"\")\n",
    "        for index in range(0, len(convo)):\n",
    "            convo[index] = convo[index].replace(\"'\", \"\")\n",
    "#         print(convo)\n",
    "        #convo is a string, need to split by comma, remove first [ and last ], and then do this\n",
    "        for i in range(0, len(convo) - 1):\n",
    "#             inputSentenceIndex = re.sub(\"[^0-9]\", \"\", convo[i])\n",
    "#             outputSentenceIndex = re.sub(\"[^0-9]\", \"\", convo[i + 1])    \n",
    "            #print(convo[i])\n",
    "            inputSentenceIndex = convo[i]\n",
    "            outputSentenceIndex = convo[i + 1]\n",
    "            if (inputSentenceIndex in lineToText) and (outputSentenceIndex in lineToText):\n",
    "                inputs.append(lineToText[inputSentenceIndex])\n",
    "                outputs.append(lineToText[outputSentenceIndex])\n",
    "                \n",
    "            \n",
    "print(len(inputs))\n",
    "# for i in range(0, 10):\n",
    "#     print(inputs[i])\n",
    "#     print(outputs[i])\n",
    "#     print(\"~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Dataset Class\n",
    "# '''\n",
    "\n",
    "class ConvoDataset(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        \n",
    "    def getitem(self, index):\n",
    "        return self.inputs[index], self.outputs[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input = inputs[0:16000]\n",
    "training_output = outputs[0:16000]\n",
    "testing_input = inputs[16000:]\n",
    "testing_output = outputs[16000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# MAKE DATA ITERABLE\n",
    "# '''\n",
    "params = {'batch_size' : 16,\n",
    "         'shuffle': True,\n",
    "         'num_workers': 1}\n",
    "\n",
    "training_set = ConvoDataset(training_input, training_output)\n",
    "training_generator = DataLoader(training_set, **params)\n",
    "\n",
    "testing_set = ConvoDataset(testing_input, testing_output)\n",
    "testing_generator = DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# '''\n",
    "# STEP 2.75: CREATE EMBEDDINGS\n",
    "# '''\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "#model = Word2Vec(inputs,size=100, window=5, min_count=5, workers=4) # download dataset to replace inputs\n",
    "#model = gensim.models.KeyedVectors.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "#gensim model created\n",
    "import torch\n",
    "\n",
    "weights = torch.FloatTensor(model.wv.vectors)\n",
    "embedding = nn.Embedding.from_pretrained(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(['<SOS>', '<EOS>'], [np.random.rand(300), np.random.rand(300)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "weights = torch.FloatTensor(model.wv.vectors)\n",
    "embedding = nn.Embedding.from_pretrained(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1453, 0.6172, 0.6165, 0.3474, 0.1037, 0.6990, 0.0521, 0.1901, 0.3776,\n",
       "        0.3883, 0.4041, 0.3574, 0.3952, 0.8900, 0.8913, 0.0297, 0.4472, 0.8572,\n",
       "        0.6891, 0.3160, 0.7748, 0.5838, 0.5794, 0.7212, 0.9374, 0.0327, 0.1464,\n",
       "        0.1327, 0.5570, 0.9236, 0.8850, 0.2076, 0.8011, 0.3624, 0.7049, 0.0183,\n",
       "        0.1303, 0.9086, 0.4756, 0.2867, 0.7380, 0.5163, 0.9921, 0.1965, 0.4111,\n",
       "        0.0532, 0.8405, 0.2368, 0.6797, 0.0812, 0.7030, 0.2844, 0.3732, 0.8184,\n",
       "        0.3131, 0.0910, 0.2042, 0.5997, 0.8267, 0.5525, 0.5999, 0.4653, 0.5116,\n",
       "        0.0468, 0.1375, 0.4523, 0.3250, 0.0458, 0.4220, 0.4426, 0.3989, 0.3325,\n",
       "        0.6994, 0.7767, 0.6663, 0.0338, 0.1991, 0.0144, 0.6819, 0.7263, 0.5545,\n",
       "        0.2266, 0.5390, 0.6937, 0.4518, 0.3735, 0.4956, 0.1749, 0.0064, 0.4725,\n",
       "        0.2901, 0.5992, 0.8727, 0.0129, 0.1018, 0.2321, 0.1934, 0.9008, 0.6081,\n",
       "        0.1060, 0.9450, 0.7688, 0.5177, 0.9638, 0.2092, 0.7477, 0.5586, 0.9034,\n",
       "        0.4990, 0.4723, 0.3300, 0.4647, 0.3935, 0.5077, 0.0867, 0.5630, 0.0897,\n",
       "        0.4150, 0.8468, 0.0089, 0.2089, 0.5776, 0.3522, 0.4714, 0.0236, 0.8471,\n",
       "        0.6633, 0.8939, 0.7450, 0.2772, 0.0715, 0.4641, 0.0477, 0.7668, 0.3345,\n",
       "        0.5649, 0.4377, 0.0140, 0.2599, 0.2933, 0.1210, 0.3363, 0.4481, 0.3075,\n",
       "        0.6580, 0.5207, 0.9136, 0.8396, 0.4941, 0.8709, 0.7658, 0.2286, 0.2966,\n",
       "        0.0712, 0.8507, 0.9996, 0.3001, 0.8082, 0.2189, 0.4700, 0.4744, 0.2191,\n",
       "        0.9028, 0.7313, 0.4246, 0.7626, 0.1366, 0.3232, 0.5336, 0.0291, 0.2138,\n",
       "        0.7067, 0.4367, 0.8174, 0.0391, 0.2324, 0.2232, 0.0831, 0.7709, 0.3572,\n",
       "        0.6187, 0.4913, 0.9898, 0.9548, 0.8540, 0.5356, 0.4325, 0.7707, 0.2652,\n",
       "        0.9546, 0.2885, 0.8815, 0.2764, 0.2801, 0.6268, 0.6984, 0.8990, 0.2727,\n",
       "        0.1404, 0.2786, 0.3926, 0.9962, 0.6386, 0.0025, 0.2312, 0.7989, 0.5443,\n",
       "        0.9362, 0.8269, 0.9286, 0.0811, 0.8925, 0.1798, 0.9927, 0.7629, 0.3665,\n",
       "        0.6363, 0.5707, 0.3629, 0.8809, 0.1603, 0.3338, 0.0712, 0.9220, 0.3354,\n",
       "        0.0315, 0.8625, 0.7077, 0.1608, 0.5411, 0.9453, 0.0111, 0.1453, 0.2614,\n",
       "        0.2937, 0.1400, 0.2460, 0.3369, 0.4172, 0.0646, 0.8764, 0.5925, 0.6287,\n",
       "        0.9468, 0.2029, 0.9327, 0.1028, 0.4592, 0.2403, 0.7248, 0.5318, 0.9699,\n",
       "        0.1889, 0.3427, 0.5030, 0.1164, 0.7172, 0.6855, 0.7765, 0.4106, 0.2604,\n",
       "        0.3456, 0.2122, 0.8141, 0.8670, 0.1129, 0.6306, 0.4397, 0.0493, 0.2624,\n",
       "        0.4585, 0.7153, 0.1224, 0.4124, 0.4699, 0.4699, 0.0534, 0.4209, 0.0050,\n",
       "        0.2681, 0.6988, 0.8154, 0.3627, 0.9712, 0.7552, 0.7443, 0.7505, 0.5608,\n",
       "        0.3537, 0.2749, 0.1631, 0.6028, 0.8291, 0.0789, 0.1351, 0.8098, 0.4363,\n",
       "        0.2933, 0.7696, 0.5292])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(torch.tensor(model.vocab[\"<EOS>\"].index, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# STEP 3: CREATE MODEL CLASS\n",
    "# '''\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_sz):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "#         self.embedding = nn.Embedding(input_sz, hidden_sz)\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_sz, hidden_sz)\n",
    "        \n",
    "    def forward(self, _input, hidden):\n",
    "        output = self.embedding(_input).view(1, 1, -1) # the -1 infers the dimension, the 1, 1 is a 1D vector\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "        \n",
    "    def hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_sz, output_sz):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_sz\n",
    "\n",
    "        #self.embedding = nn.Embedding(output_sz, hidden_sz)\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_sz, hidden_sz)\n",
    "        self.out = nn.Linear(hidden_sz, output_sz)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, _input, hidden):\n",
    "        output = self.embedding(_input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=20):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "input_ = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "for i in input_:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "\n",
    "#in translation example, first arg for encoder and second arg for attnetion is num of words in a sentence? idk if we\n",
    "#should be having that or something else?\n",
    "# model = FeedForwardModel()\n",
    "hidden_size = 256\n",
    "vocab_size = 3000000\n",
    "encoder1 = EncoderRNN(hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, vocab_size).to(device)\n",
    "\n",
    "attn_decoder1 = Attention(hidden_size, len(outputs), dropout_p=0.1).to(device)\n",
    "# attn_decoder1 = Attention(hidden_size, len(outputs), dropout_p=0.1)\n",
    "\n",
    "# trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMost of the time I use SGD. Feel free to use another optimizer if you wish.\\nWhat hyperparameters would you use/set here?\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "\"\"\"\n",
    "Most of the time I use SGD. Feel free to use another optimizer if you wish.\n",
    "What hyperparameters would you use/set here?\n",
    "\"\"\"\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "# we want to call torch.tensor() on a list of indexes\n",
    "# each sentence becomes a list of indexes --> an input tensor that we put into train()\n",
    "\n",
    "MAX_LENGTH = 20\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[model.vocab[SOS_token].index]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # Without teacher forcing: use its own predictions as the next input\n",
    "    for di in range(target_length):\n",
    "#         decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "#                 decoder_input, decoder_hidden, encoder_outputs)        \n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        if decoder_input.item() == model.vocab[EOS_token].index:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "    \n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    #pass in our data here?\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for i, (_input, _output) in enumerate(training_generator):\n",
    "\n",
    "#split input into array and make into pytorch tensor\n",
    "\n",
    "        input_words = _input.split(\" \")\n",
    "        input_indexes = [model.vocab[word].index for word in input_words]\n",
    "        input_tensor = torch.tensor(input_indexes, dtype=torch.long)\n",
    "        \n",
    "        output_words = _output.split(\" \")\n",
    "        output_indexes = [model.vocab[word].index for word in output_words]\n",
    "        output_tensor = torch.tensor(output_indexes, dtype=torch.long)\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HINT 2: for your inner for loop you need to do these steps:\n",
    "    # Load images with gradient accumulation capabilities\n",
    "    # Clear gradients w.r.t. parameters\n",
    "    # Forward pass to get output/logits\n",
    "    # Calculate Loss: softmax --> cross entropy loss\n",
    "    # Getting gradients w.r.t. parameters\n",
    "    # Updating parameters\n",
    "\n",
    "HINT 3: You may look at FF NN MNIST.ipynb if you're stuck or have no clue where to start. Yes it is difficult but you're all very capable <3\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
