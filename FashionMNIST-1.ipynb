{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the below cells until 'stop' to get your data processed and loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "SOS_token = '<SOS>'\n",
    "EOS_token = '<EOS>'\n",
    "UNK_token = '<UNK>'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop\n",
    "\n",
    "Below this block is your responsibility! Best of luck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221616\n"
     ]
    }
   ],
   "source": [
    "# STEP 2.5: CLEANING DATA\n",
    "movie_text = open('moviedialogues/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "conv_lines = open('moviedialogues/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "\n",
    "lineToText = {}  # mapping of line number to text\n",
    "# inputToOutput = {}\n",
    "inputs = []\n",
    "outputs = []\n",
    "for line in movie_text:\n",
    "    things = line.split(\"+++$+++\")\n",
    "#     print(things)\n",
    "    if (len(things) == 5):  \n",
    "#         key = re.sub(\"[^0-9]\", \"\", things[0])\n",
    "        val = things[4].translate(str.maketrans('', '', string.punctuation))\n",
    "#         lineToText[int(key)] = val\n",
    "        lineToText[things[0].replace(\" \", \"\")] = val\n",
    "\n",
    "        \n",
    "# print(lineToText[295])\n",
    "\n",
    "\n",
    "for conversation in conv_lines:\n",
    "    things = conversation.split(\"+++$+++\")\n",
    "    if (len(things) == 4):\n",
    "        convo = things[3]\n",
    "        convo = [x.strip() for x in convo.split(',')]\n",
    "        convo[0] = convo[0].replace(\"[\", \"\")\n",
    "        convo[len(convo) - 1] = convo[len(convo) - 1].replace(\"]\", \"\")\n",
    "        for index in range(0, len(convo)):\n",
    "            convo[index] = convo[index].replace(\"'\", \"\")\n",
    "#         print(convo)\n",
    "        #convo is a string, need to split by comma, remove first [ and last ], and then do this\n",
    "        for i in range(0, len(convo) - 1):\n",
    "#             inputSentenceIndex = re.sub(\"[^0-9]\", \"\", convo[i])\n",
    "#             outputSentenceIndex = re.sub(\"[^0-9]\", \"\", convo[i + 1])    \n",
    "            #print(convo[i])\n",
    "            inputSentenceIndex = convo[i]\n",
    "            outputSentenceIndex = convo[i + 1]\n",
    "            if (inputSentenceIndex in lineToText) and (outputSentenceIndex in lineToText):\n",
    "                inputs.append(lineToText[inputSentenceIndex])\n",
    "                outputs.append(lineToText[outputSentenceIndex])\n",
    "                \n",
    "            \n",
    "print(len(inputs))\n",
    "# for i in range(0, 10):\n",
    "#     print(inputs[i])\n",
    "#     print(outputs[i])\n",
    "#     print(\"~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Dataset Class\n",
    "# '''\n",
    "\n",
    "class ConvoDataset(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        iwords = self.inputs[index].split(\" \")\n",
    "        owords = self.outputs[index].split(\" \")\n",
    "        \n",
    "        iwords = list(filter(None, iwords))\n",
    "        owords = list(filter(None, owords))\n",
    "        \n",
    "#         return iwords, owords\n",
    "        _input = torch.tensor([model.vocab[word].index if word in model.vocab else model.vocab[UNK_token].index for word in iwords], dtype=torch.long)\n",
    "        _output = torch.tensor([model.vocab[word].index if word in model.vocab else model.vocab[UNK_token].index for word in owords], dtype=torch.long)\n",
    "        \n",
    "        return _input, _output \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input = inputs[0:16000]\n",
    "training_output = outputs[0:16000]\n",
    "testing_input = inputs[16000:]\n",
    "testing_output = outputs[16000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# MAKE DATA ITERABLE\n",
    "# '''\n",
    "params = {'batch_size' : 16,\n",
    "         'shuffle': True,\n",
    "         'num_workers': 1}\n",
    "\n",
    "training_set = ConvoDataset(training_input, training_output)\n",
    "training_generator = DataLoader(training_set, **params)\n",
    "\n",
    "testing_set = ConvoDataset(testing_input, testing_output)\n",
    "testing_generator = DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.7/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "# '''\n",
    "# STEP 2.75: CREATE EMBEDDINGS\n",
    "# '''\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "model = api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "# model = api.load(\"word2vec-google-news-300\")\n",
    "#model = Word2Vec(inputs,size=100, window=5, min_count=5, workers=4) # download dataset to replace inputs\n",
    "#model = gensim.models.KeyedVectors.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "#gensim model created\n",
    "import torch\n",
    "print(model.vector_size)\n",
    "\n",
    "model.add(['<SOS>', '<EOS>', '<UNK>'], [np.random.rand(50), np.random.rand(50), np.random.rand(50)])\n",
    "weights = torch.FloatTensor(model.wv.vectors)\n",
    "embedding = nn.Embedding.from_pretrained(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# STEP 3: CREATE MODEL CLASS\n",
    "# '''\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_sz):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "#         self.embedding = nn.Embedding(input_sz, hidden_sz)\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_sz, hidden_sz)\n",
    "        \n",
    "    def forward(self, _input, hidden):\n",
    "        output = self.embedding(_input).view(1, 1, -1) # the -1 infers the dimension, the 1, 1 is a 1D vector\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "        \n",
    "    def hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_sz, output_sz):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_sz\n",
    "\n",
    "        #self.embedding = nn.Embedding(output_sz, hidden_sz)\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_sz, hidden_sz)\n",
    "        self.out = nn.Linear(hidden_sz, output_sz)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, _input, hidden):\n",
    "        output = self.embedding(_input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=20):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "\n",
    "#in translation example, first arg for encoder and second arg for attnetion is num of words in a sentence? idk if we\n",
    "#should be having that or something else?\n",
    "# model = FeedForwardModel()\n",
    "# hidden_size = 300\n",
    "hidden_size = 50\n",
    "vocab_size = 400003\n",
    "encoder1 = EncoderRNN(hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, vocab_size).to(device)\n",
    "\n",
    "# attn_decoder1 = Attention(hidden_size, len(outputs), dropout_p=0.1).to(device)\n",
    "# attn_decoder1 = Attention(hidden_size, len(outputs), dropout_p=0.1)\n",
    "\n",
    "# trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 28 00:08:16 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 410.79       Driver Version: 410.79       CUDA Version: 10.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Quadro M4000        Off  | 00000000:00:05.0 Off |                  N/A |\r\n",
      "| 46%   30C    P0    42W / 120W |    544MiB /  8126MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1914      C   ...rspace/anaconda3/envs/fastai/bin/python   533MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "# we want to call torch.tensor() on a list of indexes\n",
    "# each sentence becomes a list of indexes --> an input tensor that we put into train()\n",
    "\n",
    "MAX_LENGTH = 20\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.hidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = min(input_tensor.size(0), 20) # DON'T USE MIN ITS HACKY AF\n",
    "    target_length = min(target_tensor.size(0), 20)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[model.vocab[SOS_token].index]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    # Without teacher forcing: use its own predictions as the next input\n",
    "    for di in range(target_length):\n",
    "#         decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "#                 decoder_input, decoder_hidden, encoder_outputs)        \n",
    "        decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "    \n",
    "    \n",
    "        inp = decoder_output #torch.tensor([[torch.max(decoder_output, 1)[1].item()]], dtype=torch.float).to(device)\n",
    "        tar = torch.tensor([target_tensor[di].item()], dtype=torch.long).to(device)\n",
    "            \n",
    "        loss += criterion(inp, tar)\n",
    "#         if decoder_input.item() == model.vocab[EOS_token].index:\n",
    "#             break\n",
    "    if isinstance(loss, int):\n",
    "        print(input_tensor, target_tensor)\n",
    "    else:\n",
    "        loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    if isinstance(loss, int):\n",
    "        return 0\n",
    "    else:\n",
    "        return loss.item() / target_length\n",
    "    \n",
    "    \n",
    "def indexize(string):\n",
    "    \"\"\"\n",
    "    string: sentence to indexize into word indices\n",
    "    \n",
    "    Returns: a tensor of word indices\n",
    "    \"\"\"\n",
    "    words = string.split(\" \")\n",
    "    words = list(filter(None, words))\n",
    "    words.append(\"<EOS>\")\n",
    "    indexed = torch.tensor([model.vocab[word].index if word in model.vocab else model.vocab[UNK_token].index for word in words], dtype=torch.long)\n",
    "    return indexed\n",
    "    \n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    #pass in our data here?\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    start=time.time()\n",
    "#     for _input, _output in training_generator:\n",
    "    for epoch in range(0, 10):\n",
    "        print(\"epoch: \" + str(epoch))\n",
    "\n",
    "        for idx in range(len(training_input)):\n",
    "#split input into array and make into pytorch tensor\n",
    "\n",
    "#         input_words = _input.split(\" \")\n",
    "#         input_indexes = [model.vocab[word].index for word in input_words]\n",
    "#         input_tensor = torch.tensor(input_indexes, dtype=torch.long)\n",
    "        \n",
    "#         output_words = _output.split(\" \")\n",
    "#         output_indexes = [model.vocab[word].index for word in output_words]\n",
    "#         output_tensor = torch.tensor(output_indexes, dtype=torch.long)\n",
    "            _input = indexize(training_input[idx])\n",
    "            _output = indexize(training_output[idx])\n",
    "            \n",
    "            input_tensor = _input.to(device)\n",
    "            target_tensor = _output.to(device)\n",
    "            loss_f = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss_f\n",
    "            plot_loss_total += loss_f\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                end = time.time()\n",
    "                print('training idx:[{}/{}], Loss: {:.4f}, Time: {:.2f}'\n",
    "                  .format(idx, len(training_input), print_loss_total, end-start))\n",
    "#             print('%s (%d %d%%) %.4f' % (timeSince(start, idx / n_iters),\n",
    "#                                          idx, idx / n_iters * 100, print_loss_avg))\n",
    "                print_loss_total = 0\n",
    "\n",
    "            if idx % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "\n",
    "        showPlot(plot_losses)\n",
    "    \n",
    "        torch.save(encoder1.state_dict(), 'current encoder')\n",
    "        torch.save(decoder1.state_dict(), 'current decoder')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "training idx:[0/16000], Loss: 6.1912, Time: 0.22\n",
      "training idx:[100/16000], Loss: 445.9126, Time: 13.98\n",
      "training idx:[200/16000], Loss: 484.6305, Time: 27.78\n",
      "training idx:[300/16000], Loss: 464.8628, Time: 40.21\n",
      "training idx:[400/16000], Loss: 400.0831, Time: 51.02\n",
      "training idx:[500/16000], Loss: 471.8086, Time: 64.96\n",
      "training idx:[600/16000], Loss: 477.3969, Time: 78.75\n",
      "training idx:[700/16000], Loss: 457.9997, Time: 92.32\n",
      "training idx:[800/16000], Loss: 449.6085, Time: 106.20\n",
      "training idx:[900/16000], Loss: 459.4976, Time: 121.57\n",
      "training idx:[1000/16000], Loss: 446.3420, Time: 134.95\n",
      "training idx:[1100/16000], Loss: 452.7066, Time: 149.25\n",
      "training idx:[1200/16000], Loss: 494.2113, Time: 163.32\n",
      "training idx:[1300/16000], Loss: 490.6902, Time: 179.27\n",
      "training idx:[1400/16000], Loss: 503.5374, Time: 195.70\n",
      "training idx:[1500/16000], Loss: 517.3355, Time: 213.87\n",
      "training idx:[1600/16000], Loss: 514.0556, Time: 232.25\n",
      "training idx:[1700/16000], Loss: 495.9643, Time: 248.97\n",
      "training idx:[1800/16000], Loss: 465.1141, Time: 262.38\n",
      "training idx:[1900/16000], Loss: 480.4777, Time: 276.78\n",
      "training idx:[2000/16000], Loss: 465.8173, Time: 290.09\n",
      "training idx:[2100/16000], Loss: 434.3747, Time: 303.28\n",
      "training idx:[2200/16000], Loss: 431.8663, Time: 316.39\n",
      "training idx:[2300/16000], Loss: 508.4736, Time: 333.11\n",
      "training idx:[2400/16000], Loss: 518.6734, Time: 350.03\n",
      "training idx:[2500/16000], Loss: 449.5573, Time: 364.96\n",
      "training idx:[2600/16000], Loss: 473.9739, Time: 379.44\n",
      "training idx:[2700/16000], Loss: 467.7133, Time: 393.89\n",
      "training idx:[2800/16000], Loss: 453.1312, Time: 407.70\n",
      "training idx:[2900/16000], Loss: 473.9261, Time: 422.57\n",
      "training idx:[3000/16000], Loss: 425.6407, Time: 435.59\n",
      "training idx:[3100/16000], Loss: 406.3655, Time: 449.88\n",
      "training idx:[3200/16000], Loss: 431.9244, Time: 464.99\n",
      "training idx:[3300/16000], Loss: 430.6027, Time: 480.06\n",
      "training idx:[3400/16000], Loss: 479.2781, Time: 494.98\n",
      "training idx:[3500/16000], Loss: 467.1157, Time: 509.07\n",
      "training idx:[3600/16000], Loss: 477.4508, Time: 523.50\n",
      "training idx:[3700/16000], Loss: 445.5435, Time: 537.54\n",
      "training idx:[3800/16000], Loss: 474.6419, Time: 552.68\n",
      "training idx:[3900/16000], Loss: 480.8905, Time: 569.74\n",
      "training idx:[4000/16000], Loss: 477.3454, Time: 585.44\n",
      "training idx:[4100/16000], Loss: 510.6091, Time: 601.91\n",
      "training idx:[4200/16000], Loss: 487.1392, Time: 617.38\n",
      "training idx:[4300/16000], Loss: 477.8548, Time: 633.28\n",
      "training idx:[4400/16000], Loss: 456.5842, Time: 647.05\n",
      "training idx:[4500/16000], Loss: 408.6445, Time: 659.60\n",
      "training idx:[4600/16000], Loss: 403.0190, Time: 672.33\n",
      "training idx:[4700/16000], Loss: 415.8522, Time: 686.27\n",
      "training idx:[4800/16000], Loss: 418.0616, Time: 700.30\n",
      "training idx:[4900/16000], Loss: 441.4343, Time: 715.77\n",
      "training idx:[5000/16000], Loss: 425.7730, Time: 729.22\n",
      "training idx:[5100/16000], Loss: 435.8396, Time: 743.29\n",
      "training idx:[5200/16000], Loss: 439.5545, Time: 756.59\n",
      "training idx:[5300/16000], Loss: 449.2833, Time: 770.13\n",
      "training idx:[5400/16000], Loss: 395.3444, Time: 781.34\n",
      "training idx:[5500/16000], Loss: 462.9371, Time: 795.90\n",
      "training idx:[5600/16000], Loss: 440.1281, Time: 810.34\n",
      "training idx:[5700/16000], Loss: 450.7126, Time: 825.36\n",
      "training idx:[5800/16000], Loss: 471.0158, Time: 841.49\n",
      "training idx:[5900/16000], Loss: 412.8639, Time: 855.21\n",
      "training idx:[6000/16000], Loss: 429.0790, Time: 870.11\n",
      "training idx:[6100/16000], Loss: 433.1180, Time: 882.68\n",
      "training idx:[6200/16000], Loss: 422.7209, Time: 894.72\n",
      "training idx:[6300/16000], Loss: 482.8637, Time: 909.38\n",
      "training idx:[6400/16000], Loss: 458.1277, Time: 923.47\n",
      "training idx:[6500/16000], Loss: 478.4800, Time: 938.33\n",
      "training idx:[6600/16000], Loss: 376.1131, Time: 949.56\n",
      "training idx:[6700/16000], Loss: 450.7141, Time: 962.55\n",
      "training idx:[6800/16000], Loss: 381.2193, Time: 975.29\n",
      "training idx:[6900/16000], Loss: 376.6934, Time: 987.38\n",
      "training idx:[7000/16000], Loss: 430.4431, Time: 1000.61\n",
      "training idx:[7100/16000], Loss: 456.1393, Time: 1015.59\n",
      "training idx:[7200/16000], Loss: 473.0706, Time: 1030.03\n",
      "training idx:[7300/16000], Loss: 479.4899, Time: 1044.86\n",
      "training idx:[7400/16000], Loss: 494.2718, Time: 1060.78\n",
      "training idx:[7500/16000], Loss: 397.1932, Time: 1073.33\n",
      "training idx:[7600/16000], Loss: 521.1568, Time: 1090.20\n",
      "training idx:[7700/16000], Loss: 487.1816, Time: 1105.52\n",
      "training idx:[7800/16000], Loss: 450.8515, Time: 1118.65\n",
      "training idx:[7900/16000], Loss: 481.0775, Time: 1132.55\n",
      "training idx:[8000/16000], Loss: 484.0291, Time: 1145.59\n",
      "training idx:[8100/16000], Loss: 461.6810, Time: 1159.22\n",
      "training idx:[8200/16000], Loss: 437.9048, Time: 1171.73\n",
      "training idx:[8300/16000], Loss: 476.9809, Time: 1185.46\n",
      "training idx:[8400/16000], Loss: 453.4537, Time: 1198.52\n",
      "training idx:[8500/16000], Loss: 476.7087, Time: 1214.30\n",
      "training idx:[8600/16000], Loss: 468.7958, Time: 1229.52\n",
      "training idx:[8700/16000], Loss: 493.3217, Time: 1245.80\n",
      "training idx:[8800/16000], Loss: 486.5748, Time: 1261.31\n",
      "training idx:[8900/16000], Loss: 443.8771, Time: 1275.04\n",
      "training idx:[9000/16000], Loss: 472.6731, Time: 1291.98\n",
      "training idx:[9100/16000], Loss: 496.3990, Time: 1307.05\n",
      "training idx:[9200/16000], Loss: 545.2304, Time: 1326.52\n",
      "training idx:[9300/16000], Loss: 489.0958, Time: 1342.47\n",
      "training idx:[9400/16000], Loss: 500.2449, Time: 1360.54\n",
      "training idx:[9500/16000], Loss: 525.3963, Time: 1373.60\n",
      "training idx:[9600/16000], Loss: 550.1382, Time: 1393.10\n",
      "training idx:[9700/16000], Loss: 540.9218, Time: 1413.03\n",
      "training idx:[9800/16000], Loss: 500.6367, Time: 1429.49\n",
      "training idx:[9900/16000], Loss: 451.2087, Time: 1443.72\n",
      "training idx:[10000/16000], Loss: 462.8732, Time: 1459.72\n",
      "training idx:[10100/16000], Loss: 473.2233, Time: 1474.43\n",
      "training idx:[10200/16000], Loss: 470.6217, Time: 1489.92\n",
      "training idx:[10300/16000], Loss: 448.1141, Time: 1503.89\n",
      "training idx:[10400/16000], Loss: 426.6351, Time: 1517.95\n",
      "training idx:[10500/16000], Loss: 465.7283, Time: 1532.72\n",
      "training idx:[10600/16000], Loss: 369.8831, Time: 1543.77\n",
      "training idx:[10700/16000], Loss: 413.0718, Time: 1556.65\n",
      "training idx:[10800/16000], Loss: 407.8847, Time: 1568.77\n",
      "training idx:[10900/16000], Loss: 489.8502, Time: 1584.71\n",
      "training idx:[11000/16000], Loss: 455.9103, Time: 1600.52\n",
      "training idx:[11100/16000], Loss: 465.2396, Time: 1615.92\n",
      "training idx:[11200/16000], Loss: 469.6835, Time: 1629.72\n",
      "training idx:[11300/16000], Loss: 421.2841, Time: 1639.87\n",
      "training idx:[11400/16000], Loss: 463.5851, Time: 1652.71\n",
      "training idx:[11500/16000], Loss: 455.3378, Time: 1665.50\n",
      "training idx:[11600/16000], Loss: 426.0058, Time: 1677.56\n",
      "training idx:[11700/16000], Loss: 407.8588, Time: 1688.26\n",
      "training idx:[11800/16000], Loss: 389.9650, Time: 1699.52\n",
      "training idx:[11900/16000], Loss: 375.8109, Time: 1710.16\n",
      "training idx:[12000/16000], Loss: 406.9394, Time: 1723.39\n",
      "training idx:[12100/16000], Loss: 445.8311, Time: 1735.88\n",
      "training idx:[12200/16000], Loss: 409.0377, Time: 1746.31\n",
      "training idx:[12300/16000], Loss: 428.6947, Time: 1759.51\n",
      "training idx:[12400/16000], Loss: 420.0657, Time: 1772.19\n",
      "training idx:[12500/16000], Loss: 434.9138, Time: 1786.24\n",
      "training idx:[12600/16000], Loss: 386.5436, Time: 1798.91\n",
      "training idx:[12700/16000], Loss: 372.8867, Time: 1810.77\n",
      "training idx:[12800/16000], Loss: 396.7337, Time: 1823.40\n",
      "training idx:[12900/16000], Loss: 468.3101, Time: 1840.70\n",
      "training idx:[13000/16000], Loss: 374.1564, Time: 1853.44\n",
      "training idx:[13100/16000], Loss: 497.1417, Time: 1870.07\n",
      "training idx:[13200/16000], Loss: 473.6075, Time: 1883.48\n",
      "training idx:[13300/16000], Loss: 442.1348, Time: 1898.20\n",
      "training idx:[13400/16000], Loss: 456.5403, Time: 1912.06\n",
      "training idx:[13500/16000], Loss: 448.8386, Time: 1925.94\n",
      "training idx:[13600/16000], Loss: 391.0778, Time: 1935.11\n",
      "training idx:[13700/16000], Loss: 407.1830, Time: 1947.30\n",
      "training idx:[13800/16000], Loss: 427.5005, Time: 1958.87\n",
      "training idx:[13900/16000], Loss: 426.3116, Time: 1970.46\n",
      "training idx:[14000/16000], Loss: 401.2767, Time: 1980.98\n",
      "training idx:[14100/16000], Loss: 420.9086, Time: 1994.57\n",
      "training idx:[14200/16000], Loss: 446.2769, Time: 2006.52\n",
      "training idx:[14300/16000], Loss: 497.5109, Time: 2022.07\n",
      "training idx:[14400/16000], Loss: 539.5722, Time: 2039.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training idx:[14500/16000], Loss: 506.9247, Time: 2056.18\n",
      "training idx:[14600/16000], Loss: 459.6144, Time: 2071.20\n",
      "training idx:[14700/16000], Loss: 489.0613, Time: 2089.28\n",
      "training idx:[14800/16000], Loss: 473.1476, Time: 2104.69\n",
      "training idx:[14900/16000], Loss: 488.1450, Time: 2120.27\n",
      "training idx:[15000/16000], Loss: 474.4780, Time: 2138.34\n",
      "training idx:[15100/16000], Loss: 431.8643, Time: 2152.26\n",
      "training idx:[15200/16000], Loss: 468.9610, Time: 2168.52\n",
      "training idx:[15300/16000], Loss: 496.6872, Time: 2184.70\n",
      "training idx:[15400/16000], Loss: 458.6644, Time: 2198.22\n",
      "training idx:[15500/16000], Loss: 456.0121, Time: 2210.19\n",
      "training idx:[15600/16000], Loss: 497.7836, Time: 2224.74\n",
      "training idx:[15700/16000], Loss: 481.5722, Time: 2239.46\n",
      "training idx:[15800/16000], Loss: 447.9803, Time: 2254.36\n",
      "training idx:[15900/16000], Loss: 477.4915, Time: 2268.00\n",
      "epoch: 1\n",
      "training idx:[0/16000], Loss: 506.5774, Time: 2286.68\n",
      "training idx:[100/16000], Loss: 439.6130, Time: 2300.55\n",
      "training idx:[200/16000], Loss: 477.3919, Time: 2314.48\n",
      "training idx:[300/16000], Loss: 458.3986, Time: 2326.99\n",
      "training idx:[400/16000], Loss: 391.3966, Time: 2337.81\n",
      "training idx:[500/16000], Loss: 463.1653, Time: 2351.69\n",
      "training idx:[600/16000], Loss: 469.7792, Time: 2365.44\n",
      "training idx:[700/16000], Loss: 452.7573, Time: 2378.93\n",
      "training idx:[800/16000], Loss: 441.0271, Time: 2392.79\n",
      "training idx:[900/16000], Loss: 451.0144, Time: 2408.12\n",
      "training idx:[1000/16000], Loss: 439.1969, Time: 2421.51\n",
      "training idx:[1100/16000], Loss: 446.3327, Time: 2435.80\n",
      "training idx:[1200/16000], Loss: 483.4186, Time: 2449.77\n",
      "training idx:[1300/16000], Loss: 480.4372, Time: 2465.65\n",
      "training idx:[1400/16000], Loss: 495.1723, Time: 2482.02\n",
      "training idx:[1500/16000], Loss: 508.8899, Time: 2500.24\n",
      "training idx:[1600/16000], Loss: 504.2395, Time: 2518.56\n",
      "training idx:[1700/16000], Loss: 488.0606, Time: 2535.30\n",
      "training idx:[1800/16000], Loss: 456.2551, Time: 2548.79\n",
      "training idx:[1900/16000], Loss: 470.0780, Time: 2563.29\n",
      "training idx:[2000/16000], Loss: 453.3917, Time: 2576.58\n",
      "training idx:[2100/16000], Loss: 427.4671, Time: 2589.66\n",
      "training idx:[2200/16000], Loss: 427.6542, Time: 2602.75\n",
      "training idx:[2300/16000], Loss: 498.6144, Time: 2619.51\n",
      "training idx:[2400/16000], Loss: 507.6659, Time: 2636.29\n",
      "training idx:[2500/16000], Loss: 443.2822, Time: 2650.96\n",
      "training idx:[2600/16000], Loss: 465.3705, Time: 2665.22\n",
      "training idx:[2700/16000], Loss: 460.4065, Time: 2679.47\n",
      "training idx:[2800/16000], Loss: 445.6234, Time: 2693.23\n",
      "training idx:[2900/16000], Loss: 465.6746, Time: 2708.06\n",
      "training idx:[3000/16000], Loss: 422.3166, Time: 2721.01\n",
      "training idx:[3100/16000], Loss: 400.5043, Time: 2735.17\n",
      "training idx:[3200/16000], Loss: 425.7183, Time: 2750.24\n",
      "training idx:[3300/16000], Loss: 423.7174, Time: 2765.22\n",
      "training idx:[3400/16000], Loss: 472.9256, Time: 2780.02\n",
      "training idx:[3500/16000], Loss: 460.2719, Time: 2793.87\n",
      "training idx:[3600/16000], Loss: 468.6765, Time: 2808.06\n",
      "training idx:[3700/16000], Loss: 438.6938, Time: 2822.02\n",
      "training idx:[3800/16000], Loss: 465.1932, Time: 2837.04\n",
      "training idx:[3900/16000], Loss: 473.7195, Time: 2854.00\n",
      "training idx:[4000/16000], Loss: 469.0399, Time: 2869.60\n",
      "training idx:[4100/16000], Loss: 501.8306, Time: 2885.98\n",
      "training idx:[4200/16000], Loss: 480.0192, Time: 2901.34\n",
      "training idx:[4300/16000], Loss: 471.2659, Time: 2916.99\n",
      "training idx:[4400/16000], Loss: 449.7048, Time: 2930.72\n",
      "training idx:[4500/16000], Loss: 401.6046, Time: 2943.25\n",
      "training idx:[4600/16000], Loss: 397.1658, Time: 2955.89\n",
      "training idx:[4700/16000], Loss: 408.9221, Time: 2969.76\n",
      "training idx:[4800/16000], Loss: 414.1692, Time: 2983.68\n",
      "training idx:[4900/16000], Loss: 435.8737, Time: 2999.12\n",
      "training idx:[5000/16000], Loss: 418.3466, Time: 3012.47\n",
      "training idx:[5100/16000], Loss: 429.2559, Time: 3026.49\n",
      "training idx:[5200/16000], Loss: 432.0159, Time: 3039.78\n",
      "training idx:[5300/16000], Loss: 439.6520, Time: 3053.19\n",
      "training idx:[5400/16000], Loss: 389.0021, Time: 3064.38\n",
      "training idx:[5500/16000], Loss: 454.6469, Time: 3078.70\n",
      "training idx:[5600/16000], Loss: 435.0709, Time: 3092.92\n",
      "training idx:[5700/16000], Loss: 443.6170, Time: 3107.83\n",
      "training idx:[5800/16000], Loss: 464.0495, Time: 3123.78\n",
      "training idx:[5900/16000], Loss: 406.7986, Time: 3137.49\n",
      "training idx:[6000/16000], Loss: 422.3705, Time: 3152.27\n",
      "training idx:[6100/16000], Loss: 428.2974, Time: 3164.86\n",
      "training idx:[6200/16000], Loss: 417.6292, Time: 3177.00\n",
      "training idx:[6300/16000], Loss: 476.7357, Time: 3191.82\n",
      "training idx:[6400/16000], Loss: 450.1906, Time: 3205.97\n",
      "training idx:[6500/16000], Loss: 469.5910, Time: 3220.97\n",
      "training idx:[6600/16000], Loss: 372.4511, Time: 3232.25\n",
      "training idx:[6700/16000], Loss: 443.9158, Time: 3245.28\n",
      "training idx:[6800/16000], Loss: 376.8613, Time: 3258.05\n",
      "training idx:[6900/16000], Loss: 372.6624, Time: 3270.23\n",
      "training idx:[7000/16000], Loss: 424.6567, Time: 3283.65\n",
      "training idx:[7100/16000], Loss: 450.1478, Time: 3298.89\n",
      "training idx:[7200/16000], Loss: 466.5153, Time: 3313.60\n",
      "training idx:[7300/16000], Loss: 472.3691, Time: 3328.60\n",
      "training idx:[7400/16000], Loss: 485.7813, Time: 3344.59\n",
      "training idx:[7500/16000], Loss: 391.9593, Time: 3357.15\n",
      "training idx:[7600/16000], Loss: 511.9786, Time: 3373.96\n",
      "training idx:[7700/16000], Loss: 475.5093, Time: 3389.24\n",
      "training idx:[7800/16000], Loss: 442.5140, Time: 3402.34\n",
      "training idx:[7900/16000], Loss: 471.9915, Time: 3416.05\n",
      "training idx:[8000/16000], Loss: 474.0341, Time: 3428.93\n",
      "training idx:[8100/16000], Loss: 455.1168, Time: 3442.40\n",
      "training idx:[8200/16000], Loss: 433.5322, Time: 3454.73\n",
      "training idx:[8300/16000], Loss: 470.3001, Time: 3468.60\n",
      "training idx:[8400/16000], Loss: 447.5692, Time: 3481.93\n",
      "training idx:[8500/16000], Loss: 470.1197, Time: 3498.03\n",
      "training idx:[8600/16000], Loss: 462.1086, Time: 3513.49\n",
      "training idx:[8700/16000], Loss: 487.7355, Time: 3530.04\n",
      "training idx:[8800/16000], Loss: 479.3706, Time: 3545.61\n",
      "training idx:[8900/16000], Loss: 438.3447, Time: 3559.31\n",
      "training idx:[9000/16000], Loss: 466.5654, Time: 3576.26\n",
      "training idx:[9100/16000], Loss: 489.5093, Time: 3591.36\n",
      "training idx:[9200/16000], Loss: 536.8282, Time: 3610.76\n",
      "training idx:[9300/16000], Loss: 484.1222, Time: 3626.57\n",
      "training idx:[9400/16000], Loss: 494.3326, Time: 3644.72\n",
      "training idx:[9500/16000], Loss: 513.8081, Time: 3657.81\n",
      "training idx:[9600/16000], Loss: 540.7174, Time: 3677.33\n",
      "training idx:[9700/16000], Loss: 532.5889, Time: 3697.23\n",
      "training idx:[9800/16000], Loss: 493.4071, Time: 3713.67\n",
      "training idx:[9900/16000], Loss: 444.0135, Time: 3727.87\n",
      "training idx:[10000/16000], Loss: 457.0836, Time: 3743.59\n",
      "training idx:[10100/16000], Loss: 465.6408, Time: 3758.15\n",
      "training idx:[10200/16000], Loss: 464.0420, Time: 3773.48\n",
      "training idx:[10300/16000], Loss: 443.0401, Time: 3787.40\n",
      "training idx:[10400/16000], Loss: 421.7949, Time: 3801.39\n",
      "training idx:[10500/16000], Loss: 458.9052, Time: 3816.09\n",
      "training idx:[10600/16000], Loss: 366.3577, Time: 3827.20\n",
      "training idx:[10700/16000], Loss: 408.7338, Time: 3840.09\n",
      "training idx:[10800/16000], Loss: 403.6979, Time: 3852.23\n",
      "training idx:[10900/16000], Loss: 481.8893, Time: 3868.25\n",
      "training idx:[11000/16000], Loss: 448.0238, Time: 3884.08\n",
      "training idx:[11100/16000], Loss: 457.6703, Time: 3899.51\n",
      "training idx:[11200/16000], Loss: 461.2598, Time: 3913.29\n",
      "training idx:[11300/16000], Loss: 416.1757, Time: 3923.43\n",
      "training idx:[11400/16000], Loss: 455.1307, Time: 3936.24\n",
      "training idx:[11500/16000], Loss: 450.5581, Time: 3949.11\n",
      "training idx:[11600/16000], Loss: 419.8767, Time: 3961.14\n",
      "training idx:[11700/16000], Loss: 402.6720, Time: 3971.74\n",
      "training idx:[11800/16000], Loss: 385.2752, Time: 3982.93\n",
      "training idx:[11900/16000], Loss: 370.2709, Time: 3993.58\n",
      "training idx:[12000/16000], Loss: 402.5835, Time: 4006.76\n",
      "training idx:[12100/16000], Loss: 440.6171, Time: 4019.31\n",
      "training idx:[12200/16000], Loss: 403.3147, Time: 4029.75\n",
      "training idx:[12300/16000], Loss: 423.0365, Time: 4043.05\n",
      "training idx:[12400/16000], Loss: 415.7204, Time: 4055.68\n",
      "training idx:[12500/16000], Loss: 428.8000, Time: 4069.69\n",
      "training idx:[12600/16000], Loss: 381.9529, Time: 4082.39\n",
      "training idx:[12700/16000], Loss: 369.1041, Time: 4094.17\n",
      "training idx:[12800/16000], Loss: 392.1170, Time: 4106.79\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder1, decoder1, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=20):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = indexize(sentence).to(device)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.hidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "#             encoder_outputs[ei] += encoder_output[0, 0]\n",
    "        decoder_input = torch.tensor([[model.vocab[SOS_token].index]],device=device)  # SOS\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "#         decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "#             decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            print(topv)\n",
    "            if topi.item() == 400001:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(model.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words #, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-12.3147]], device='cuda:0')\n",
      "tensor([[-12.2791]], device='cuda:0')\n",
      "tensor([[-12.3090]], device='cuda:0')\n",
      "tensor([[-12.3199]], device='cuda:0')\n",
      "tensor([[-12.3953]], device='cuda:0')\n",
      "tensor([[-12.3737]], device='cuda:0')\n",
      "tensor([[-12.3616]], device='cuda:0')\n",
      "tensor([[-12.3071]], device='cuda:0')\n",
      "tensor([[-12.2213]], device='cuda:0')\n",
      "tensor([[-12.3046]], device='cuda:0')\n",
      "tensor([[-12.3837]], device='cuda:0')\n",
      "tensor([[-12.3477]], device='cuda:0')\n",
      "tensor([[-12.3476]], device='cuda:0')\n",
      "tensor([[-12.2501]], device='cuda:0')\n",
      "tensor([[-12.2379]], device='cuda:0')\n",
      "tensor([[-12.2039]], device='cuda:0')\n",
      "tensor([[-12.3406]], device='cuda:0')\n",
      "tensor([[-12.2950]], device='cuda:0')\n",
      "tensor([[-12.2031]], device='cuda:0')\n",
      "tensor([[-12.2358]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['boudou',\n",
       " 'inconsolable',\n",
       " 'super-strong',\n",
       " 'marquessate',\n",
       " 'born-again',\n",
       " 'besseghir',\n",
       " '32.75',\n",
       " 'inconsolable',\n",
       " 'redivide',\n",
       " 'beetz',\n",
       " 'awesomely',\n",
       " 'antigens',\n",
       " 'atriplex',\n",
       " 'chubar',\n",
       " 'euphorbiaceae',\n",
       " 'neuman',\n",
       " 'half-timbered',\n",
       " 'half-timbered',\n",
       " 'aquib',\n",
       " 'rigoberto']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder1, decoder1, \"hello how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([400002,     88, 400002, 400001])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexize(\"They do not!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
