{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic 7 steps for building models in general are listed so:\n",
    "\n",
    "1. Load Dataset\n",
    "2. Make Dataset Iterable\n",
    "3. Create Model Class\n",
    "4. Instantiate Model Class\n",
    "5. Instantiate Loss Class\n",
    "6. Instantiate Optimizer Class\n",
    "7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  import sys\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.7/site-packages/ipykernel_launcher.py:20: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>category_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000001.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000002.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000003.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000004.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000005.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000006.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000007.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000008.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000009.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000010.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000011.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000012.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000013.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000014.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000015.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000016.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000017.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000018.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000019.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000020.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000021.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000022.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000023.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000024.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000025.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000026.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000027.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000028.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000029.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000030.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289192</th>\n",
       "      <td>img/Paisley_Maxi_Cami_Dress/img_00000024.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289193</th>\n",
       "      <td>img/Paisley_Maxi_Cami_Dress/img_00000025.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289194</th>\n",
       "      <td>img/Paisley_Maxi_Cami_Dress/img_00000026.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289195</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000028.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289196</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000029.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289197</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000030.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289198</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000031.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289199</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000032.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289200</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000033.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289201</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000034.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289202</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000035.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289203</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000036.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289204</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000037.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289205</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000038.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289206</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000039.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289207</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000040.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289208</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000041.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289209</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000042.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289210</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000043.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289211</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000044.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289212</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000045.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289213</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000046.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289214</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000047.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289215</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000048.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289216</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000049.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289217</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000050.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289218</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000051.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289219</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000052.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289220</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000053.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289221</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000054.jpg</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289222 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_name  category_label\n",
       "0         img/Sheer_Pleated-Front_Blouse/img_00000001.jpg               3\n",
       "1         img/Sheer_Pleated-Front_Blouse/img_00000002.jpg               3\n",
       "2         img/Sheer_Pleated-Front_Blouse/img_00000003.jpg               3\n",
       "3         img/Sheer_Pleated-Front_Blouse/img_00000004.jpg               3\n",
       "4         img/Sheer_Pleated-Front_Blouse/img_00000005.jpg               3\n",
       "5         img/Sheer_Pleated-Front_Blouse/img_00000006.jpg               3\n",
       "6         img/Sheer_Pleated-Front_Blouse/img_00000007.jpg               3\n",
       "7         img/Sheer_Pleated-Front_Blouse/img_00000008.jpg               3\n",
       "8         img/Sheer_Pleated-Front_Blouse/img_00000009.jpg               3\n",
       "9         img/Sheer_Pleated-Front_Blouse/img_00000010.jpg               3\n",
       "10        img/Sheer_Pleated-Front_Blouse/img_00000011.jpg               3\n",
       "11        img/Sheer_Pleated-Front_Blouse/img_00000012.jpg               3\n",
       "12        img/Sheer_Pleated-Front_Blouse/img_00000013.jpg               3\n",
       "13        img/Sheer_Pleated-Front_Blouse/img_00000014.jpg               3\n",
       "14        img/Sheer_Pleated-Front_Blouse/img_00000015.jpg               3\n",
       "15        img/Sheer_Pleated-Front_Blouse/img_00000016.jpg               3\n",
       "16        img/Sheer_Pleated-Front_Blouse/img_00000017.jpg               3\n",
       "17        img/Sheer_Pleated-Front_Blouse/img_00000018.jpg               3\n",
       "18        img/Sheer_Pleated-Front_Blouse/img_00000019.jpg               3\n",
       "19        img/Sheer_Pleated-Front_Blouse/img_00000020.jpg               3\n",
       "20        img/Sheer_Pleated-Front_Blouse/img_00000021.jpg               3\n",
       "21        img/Sheer_Pleated-Front_Blouse/img_00000022.jpg               3\n",
       "22        img/Sheer_Pleated-Front_Blouse/img_00000023.jpg               3\n",
       "23        img/Sheer_Pleated-Front_Blouse/img_00000024.jpg               3\n",
       "24        img/Sheer_Pleated-Front_Blouse/img_00000025.jpg               3\n",
       "25        img/Sheer_Pleated-Front_Blouse/img_00000026.jpg               3\n",
       "26        img/Sheer_Pleated-Front_Blouse/img_00000027.jpg               3\n",
       "27        img/Sheer_Pleated-Front_Blouse/img_00000028.jpg               3\n",
       "28        img/Sheer_Pleated-Front_Blouse/img_00000029.jpg               3\n",
       "29        img/Sheer_Pleated-Front_Blouse/img_00000030.jpg               3\n",
       "...                                                   ...             ...\n",
       "289192       img/Paisley_Maxi_Cami_Dress/img_00000024.jpg              41\n",
       "289193       img/Paisley_Maxi_Cami_Dress/img_00000025.jpg              41\n",
       "289194       img/Paisley_Maxi_Cami_Dress/img_00000026.jpg              41\n",
       "289195  img/Paisley_Print_Babydoll_Dress/img_00000028.jpg              41\n",
       "289196  img/Paisley_Print_Babydoll_Dress/img_00000029.jpg              41\n",
       "289197  img/Paisley_Print_Babydoll_Dress/img_00000030.jpg              41\n",
       "289198  img/Paisley_Print_Babydoll_Dress/img_00000031.jpg              41\n",
       "289199  img/Paisley_Print_Babydoll_Dress/img_00000032.jpg              41\n",
       "289200  img/Paisley_Print_Babydoll_Dress/img_00000033.jpg              41\n",
       "289201  img/Paisley_Print_Babydoll_Dress/img_00000034.jpg              41\n",
       "289202  img/Paisley_Print_Babydoll_Dress/img_00000035.jpg              41\n",
       "289203  img/Paisley_Print_Babydoll_Dress/img_00000036.jpg              41\n",
       "289204  img/Paisley_Print_Babydoll_Dress/img_00000037.jpg              41\n",
       "289205  img/Paisley_Print_Babydoll_Dress/img_00000038.jpg              41\n",
       "289206  img/Paisley_Print_Babydoll_Dress/img_00000039.jpg              41\n",
       "289207  img/Paisley_Print_Babydoll_Dress/img_00000040.jpg              41\n",
       "289208  img/Paisley_Print_Babydoll_Dress/img_00000041.jpg              41\n",
       "289209  img/Paisley_Print_Babydoll_Dress/img_00000042.jpg              41\n",
       "289210  img/Paisley_Print_Babydoll_Dress/img_00000043.jpg              41\n",
       "289211  img/Paisley_Print_Babydoll_Dress/img_00000044.jpg              41\n",
       "289212  img/Paisley_Print_Babydoll_Dress/img_00000045.jpg              41\n",
       "289213  img/Paisley_Print_Babydoll_Dress/img_00000046.jpg              41\n",
       "289214  img/Paisley_Print_Babydoll_Dress/img_00000047.jpg              41\n",
       "289215  img/Paisley_Print_Babydoll_Dress/img_00000048.jpg              41\n",
       "289216  img/Paisley_Print_Babydoll_Dress/img_00000049.jpg              41\n",
       "289217  img/Paisley_Print_Babydoll_Dress/img_00000050.jpg              41\n",
       "289218  img/Paisley_Print_Babydoll_Dress/img_00000051.jpg              41\n",
       "289219  img/Paisley_Print_Babydoll_Dress/img_00000052.jpg              41\n",
       "289220  img/Paisley_Print_Babydoll_Dress/img_00000053.jpg              41\n",
       "289221  img/Paisley_Print_Babydoll_Dress/img_00000054.jpg              41\n",
       "\n",
       "[289222 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "STEP 1: LOAD DATASET\n",
    "'''\n",
    "# test_df = pd.read_csv('fashionmnist/fashion-mnist_test.csv')\n",
    "# test_df_labels = test_df['label']\n",
    "# test_pixels_df = test_df.drop('label', axis=1)\n",
    "all_df = pd.read_table('list_eval_partition.txt', delim_whitespace=True)\n",
    "validation_df = all_df[all_df['evaluation_status'].str.contains('val')]\n",
    "# np.random.shuffle(validation_df)\n",
    "validation_df = validation_df.drop(['evaluation_status'], axis=1)\n",
    "\n",
    "train_df = all_df[all_df['evaluation_status'].str.contains('train')]\n",
    "# np.random.shuffle(train_df)\n",
    "train_df = train_df.drop(['evaluation_status'], axis=1)\n",
    "\n",
    "test_df = all_df[all_df['evaluation_status'].str.contains('test')]\n",
    "# np.random.shuffle(test_df)\n",
    "test_df = test_df.drop(['evaluation_status'], axis=1)\n",
    "\n",
    "labels_df = pd.read_table('list_category_img.txt', delim_whitespace=True)\n",
    "labels_df\n",
    "\n",
    "# train_df = pd.read_csv('fashionmnist/fashion-mnist_train.csv')\n",
    "# train_pixels_df = train_df.drop('label', axis=1)\n",
    "# train_df_labels = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(image_name):\n",
    "    category_label = labels_df[labels_df['image_name'].str.match(image_name)].iloc[0]['category_label']\n",
    "    create_new = np.zeros(50)\n",
    "    create_new[category_label - 1] = 1\n",
    "    return create_new, category_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41    72158\n",
       "18    36887\n",
       "3     24557\n",
       "32    19666\n",
       "17    15429\n",
       "33    14773\n",
       "6     13311\n",
       "16    13123\n",
       "11    10467\n",
       "19    10078\n",
       "2      7495\n",
       "48     7408\n",
       "26     7076\n",
       "42     6153\n",
       "30     5013\n",
       "29     4416\n",
       "10     4048\n",
       "34     3048\n",
       "44     2294\n",
       "39     2120\n",
       "24     1669\n",
       "35     1106\n",
       "15      791\n",
       "12      748\n",
       "9       716\n",
       "13      676\n",
       "27      594\n",
       "22      527\n",
       "23      486\n",
       "36      386\n",
       "5       330\n",
       "7       324\n",
       "4       309\n",
       "1       160\n",
       "47      150\n",
       "20      146\n",
       "43      126\n",
       "14       97\n",
       "21       77\n",
       "46       70\n",
       "37       54\n",
       "25       49\n",
       "28       45\n",
       "31       32\n",
       "8        17\n",
       "40       17\n",
       "Name: category_label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = labels_df[\"category_label\"].value_counts()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'argmax'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e8d59d735606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \"\"\"\n\u001b[0;32m-> 1037\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# a downstream library like 'pandas'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "np.unique(np.argmax(labelvalidation, axis=1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labeltrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a0ede20c1ce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeltrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'labeltrain' is not defined"
     ]
    }
   ],
   "source": [
    "np.unique(np.argmax(labeltrain, axis=1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-73e766be88a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mfiftyimagesArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfiftyimagesArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-d668326f8bed>\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(image_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcategory_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcreate_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcreate_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory_label\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, pat, case, flags, na)\u001b[0m\n\u001b[1;32m   2526\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2528\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2529\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mstr_match\u001b[0;34m(arr, pat, case, flags, na)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_na_map\u001b[0;34m(f, arr, na_result, dtype)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# should really _check_ for NA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m_map\u001b[0;34m(f, arr, na_mask, na_value, dtype)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m# Reraise the exception if callable `f` got wrong number of args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_na_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "allimagesvalidation = []\n",
    "labelvalidation = []\n",
    "fiftyimagesArray = np.zeros(50)\n",
    "while len(labelvalidation) < 500:\n",
    "#     create random number\n",
    "    x = np.random.choice(20000)\n",
    "    img_filepath = validation_df.iloc[x]['image_name']\n",
    "    im = Image.open(img_filepath)\n",
    "    label, category = func(img_filepath)\n",
    "    fiftyimagesArray[category - 1] += 1\n",
    "    if fiftyimagesArray[category - 1] < 50:\n",
    "        labelvalidation.append(label)\n",
    "        imarr = np.uint8(np.asarray(im.convert('RGB').resize((224,224))))\n",
    "        imarr = (imarr - imarr.mean())/imarr.std()\n",
    "        allimagesvalidation.append(imarr)\n",
    "\n",
    "# allimagestrain = []\n",
    "# labeltrain = []\n",
    "# for index in range(250):\n",
    "#     x = np.random.choice(50000)\n",
    "#     img_filepath = train_df.iloc[x]['image_name']\n",
    "#     im = Image.open(img_filepath)\n",
    "#     labeltrain.append(func(img_filepath))\n",
    "#     imarr = np.uint8(np.asarray(im.convert('RGB').resize((224,224))))\n",
    "#     imarr = (imarr - imarr.mean())/imarr.std()\n",
    "#     allimagestrain.append(imarr)\n",
    "\n",
    "# allimagestest = []\n",
    "# labeltest = []\n",
    "# for index in range(10000):\n",
    "#     img_filepath = test_df.iloc[index]['image_name']\n",
    "#     im = Image.open(img_filepath)\n",
    "#     labeltest.append(func(img_filepath))\n",
    "#     imarr = np.uint8(np.asarray(im.convert('RGB').resize((224,224))))\n",
    "#     #imarr = np.round((imarr - imarr.mean())/imarr.std())\n",
    "#     allimagestest.append(imarr)\n",
    "# im = Image.open('414m1dOolTL._SX342_.jpg')\n",
    "# imarr = np.uint8(np.asarray(im.convert('RGB').resize((224,224))))\n",
    "\n",
    "fiftyimagesArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# STEP 1.5: defining and instantiating Dataset subclass \n",
    "# '''\n",
    "\n",
    "# '''\n",
    "# This is our custom Dataset class. Remember from 1st meeting that we need this to pipeline our data into training our model.\n",
    "\n",
    "# The pipeline is important!!! At larger scale, machine learning can get bottlenecked at disk reads (in image classification for example)\n",
    "# so understanding the various stages is important. We don't have to worry about that kind of stuff now since we're just creating small\n",
    "# project models as opposed to complex production models.\n",
    "\n",
    "# NOTE: this is not the only way to create a dataset. An alternative is to simply pass in a dataframe that contains both pixel and label data.\n",
    "# Then we can index the label and pixel data inside of __getitem__ as opposed to separating labels and pixel data before hand like I did.\n",
    "# '''\n",
    "# class FashionDataset(Dataset):\n",
    "#     def __init__(self, dataframe, labels):\n",
    "#         self.labels = torch.LongTensor(labels)\n",
    "#         self.df = dataframe\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         # I'm using .loc to access the row of the dataframe by index\n",
    "#         a = self.df.loc[index]\n",
    "# #         a = (a - np.mean(a))/np.std(a)\n",
    "#         img = torch.Tensor(a)\n",
    "#         label = self.labels[index]\n",
    "#         return img, label\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "    \n",
    "# '''\n",
    "# This class is for providing image data as (1, 28, 28) tensor as opposed to a (784) tensor. You\n",
    "# use these for conv2d layers which are powerful for image recognition!\n",
    "\n",
    "# NOTE: Please note that I normalized the data VERY INCORRECTLY. Here I am normalizing the data across \n",
    "# each sample individually which is not good. I should be normalizing across the ENTIRE training data set.\n",
    "\n",
    "# Also, when I create the test dataset I should normalize it based on the TRAINING set's mean and standard deviation.\n",
    "# Since the model is trained on the training data, we want to make sure that we transform the test data the same way we\n",
    "# transform the training data. Otherwise it's like training a model to do one job and then testing it by on another job.\n",
    "# '''\n",
    "# class Fashion2DDataset(Dataset):\n",
    "#     def __init__(self, dataframe, labels):\n",
    "#         self.labels = torch.LongTensor(labels)\n",
    "#         self.df = dataframe\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         # I'm using .loc to access the row of the dataframe by index\n",
    "#         a = self.df.loc[index]\n",
    "#         a = (a - np.mean(a))/np.std(a)\n",
    "#         a = np.split(a, 28)\n",
    "#         a = np.array([a])\n",
    "#         img = torch.Tensor(a)\n",
    "        \n",
    "#         label = self.labels[index]\n",
    "#         return img, label\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "class ClothingDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.labels = labels\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        \n",
    "        trans = transforms.ToTensor()\n",
    "        img = trans(img).float()\n",
    "        \n",
    "        label = self.labels[index]\n",
    "        label = torch.LongTensor(label)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "# train_dataset = Fashion2DDataset(train_pixels_df, train_df_labels.values)\n",
    "# test_dataset = Fashion2DDataset(test_pixels_df, test_df_labels.values)\n",
    "\n",
    "# batch_size = 100\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "#                                            batch_size=batch_size, \n",
    "#                                            shuffle=True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "#                                           batch_size=batch_size, \n",
    "#  shuffle=False)\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "train_dataset = ClothingDataset(allimagestrain, labeltrain)\n",
    "validation_dataset = ClothingDataset(allimagesvalidation, labelvalidation) \n",
    "# test_dataset = ClothingDataset(allimagestest, labeltest)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,                                             \n",
    "                                           shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "#                                           batch_size=batch_size,\n",
    "#                                           shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, \n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "# class FeedforwardNeuralNetModel(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#         super(FeedforwardNeuralNetModel, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.fc1(x)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc2(out)\n",
    "#         return out\n",
    "    \n",
    "class ConvolutionalNeuralNetModel(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(ConvolutionalNeuralNetModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=56, stride=2, padding=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(10)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        self.fc = nn.Linear(19360, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "#input_dim = 224*224\n",
    "#hidden_dim = 5000\n",
    "output_dim = 50 \n",
    "\n",
    "# model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "model = ConvolutionalNeuralNetModel(output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "\"\"\"\n",
    "Most of the time I use SGD. Feel free to use another optimizer if you wish.\n",
    "What hyperparameters would you use/set here?\n",
    "\"\"\"\n",
    "learning_rate = .1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1. Loss: 3.9753973484039307. Accuracy: 14\n",
      "Iteration: 2. Loss: 20.483705520629883. Accuracy: 16\n",
      "Iteration: 3. Loss: 16.024063110351562. Accuracy: 6\n",
      "Iteration: 4. Loss: 3.061910390853882. Accuracy: 12\n",
      "Iteration: 5. Loss: 3.4482686519622803. Accuracy: 12\n",
      "Iteration: 6. Loss: 3.6505391597747803. Accuracy: 10\n",
      "Iteration: 7. Loss: 3.1929738521575928. Accuracy: 22\n",
      "Iteration: 8. Loss: 3.5644125938415527. Accuracy: 10\n",
      "Iteration: 9. Loss: 3.4005463123321533. Accuracy: 16\n",
      "Iteration: 10. Loss: 2.9376001358032227. Accuracy: 16\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "losses = []\n",
    "accuracies = []\n",
    "for epoch in range(1):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images with gradient accumulation capabilities\n",
    "#         images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        labels = torch.max(labels,1)[1]\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 1 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in validation_loader:\n",
    "                # Load images with gradient accumulation capabilities\n",
    "                # images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                labels = torch.max(labels,1)[1]\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy =  100 * correct / total\n",
    "            \n",
    "            accuracies.append(accuracy)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
