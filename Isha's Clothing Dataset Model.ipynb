{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to build a CNN model that can accurately categorize images of clothing based on type of clothing such as dress, shirt, pants, top, etc. Ideally, an accuracy of at least 90% is optimal for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic 7 steps for building models in general are listed:\n",
    "\n",
    "1. Load Dataset\n",
    "2. Make Dataset Iterable\n",
    "3. Create Model Class\n",
    "4. Instantiate Model Class\n",
    "5. Instantiate Loss Class\n",
    "6. Instantiate Optimizer Class\n",
    "7. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyton 2 and 3 support\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from vis_utils import *\n",
    "import random;\n",
    "import math;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>evaluation_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000001.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000002.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000003.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000004.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000005.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000006.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000007.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000008.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000009.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000010.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000011.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000012.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000013.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000014.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000015.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000016.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000017.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000018.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000019.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000020.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000021.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000022.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000023.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000024.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000025.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000026.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000027.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000028.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000029.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>img/Sheer_Pleated-Front_Blouse/img_00000030.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289192</th>\n",
       "      <td>img/Paisley_Maxi_Cami_Dress/img_00000024.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289193</th>\n",
       "      <td>img/Paisley_Maxi_Cami_Dress/img_00000025.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289194</th>\n",
       "      <td>img/Paisley_Maxi_Cami_Dress/img_00000026.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289195</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000028.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289196</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000029.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289197</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000030.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289198</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000031.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289199</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000032.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289200</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000033.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289201</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000034.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289202</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000035.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289203</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000036.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289204</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000037.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289205</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000038.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289206</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000039.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289207</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000040.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289208</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000041.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289209</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000042.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289210</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000043.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289211</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000044.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289212</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000045.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289213</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000046.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289214</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000047.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289215</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000048.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289216</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000049.jpg</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289217</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000050.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289218</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000051.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289219</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000052.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289220</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000053.jpg</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289221</th>\n",
       "      <td>img/Paisley_Print_Babydoll_Dress/img_00000054.jpg</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289222 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image_name evaluation_status\n",
       "0         img/Sheer_Pleated-Front_Blouse/img_00000001.jpg             train\n",
       "1         img/Sheer_Pleated-Front_Blouse/img_00000002.jpg             train\n",
       "2         img/Sheer_Pleated-Front_Blouse/img_00000003.jpg               val\n",
       "3         img/Sheer_Pleated-Front_Blouse/img_00000004.jpg             train\n",
       "4         img/Sheer_Pleated-Front_Blouse/img_00000005.jpg              test\n",
       "5         img/Sheer_Pleated-Front_Blouse/img_00000006.jpg               val\n",
       "6         img/Sheer_Pleated-Front_Blouse/img_00000007.jpg              test\n",
       "7         img/Sheer_Pleated-Front_Blouse/img_00000008.jpg             train\n",
       "8         img/Sheer_Pleated-Front_Blouse/img_00000009.jpg             train\n",
       "9         img/Sheer_Pleated-Front_Blouse/img_00000010.jpg             train\n",
       "10        img/Sheer_Pleated-Front_Blouse/img_00000011.jpg             train\n",
       "11        img/Sheer_Pleated-Front_Blouse/img_00000012.jpg             train\n",
       "12        img/Sheer_Pleated-Front_Blouse/img_00000013.jpg              test\n",
       "13        img/Sheer_Pleated-Front_Blouse/img_00000014.jpg             train\n",
       "14        img/Sheer_Pleated-Front_Blouse/img_00000015.jpg               val\n",
       "15        img/Sheer_Pleated-Front_Blouse/img_00000016.jpg             train\n",
       "16        img/Sheer_Pleated-Front_Blouse/img_00000017.jpg             train\n",
       "17        img/Sheer_Pleated-Front_Blouse/img_00000018.jpg             train\n",
       "18        img/Sheer_Pleated-Front_Blouse/img_00000019.jpg              test\n",
       "19        img/Sheer_Pleated-Front_Blouse/img_00000020.jpg              test\n",
       "20        img/Sheer_Pleated-Front_Blouse/img_00000021.jpg             train\n",
       "21        img/Sheer_Pleated-Front_Blouse/img_00000022.jpg             train\n",
       "22        img/Sheer_Pleated-Front_Blouse/img_00000023.jpg             train\n",
       "23        img/Sheer_Pleated-Front_Blouse/img_00000024.jpg             train\n",
       "24        img/Sheer_Pleated-Front_Blouse/img_00000025.jpg             train\n",
       "25        img/Sheer_Pleated-Front_Blouse/img_00000026.jpg             train\n",
       "26        img/Sheer_Pleated-Front_Blouse/img_00000027.jpg               val\n",
       "27        img/Sheer_Pleated-Front_Blouse/img_00000028.jpg               val\n",
       "28        img/Sheer_Pleated-Front_Blouse/img_00000029.jpg              test\n",
       "29        img/Sheer_Pleated-Front_Blouse/img_00000030.jpg             train\n",
       "...                                                   ...               ...\n",
       "289192       img/Paisley_Maxi_Cami_Dress/img_00000024.jpg             train\n",
       "289193       img/Paisley_Maxi_Cami_Dress/img_00000025.jpg             train\n",
       "289194       img/Paisley_Maxi_Cami_Dress/img_00000026.jpg               val\n",
       "289195  img/Paisley_Print_Babydoll_Dress/img_00000028.jpg             train\n",
       "289196  img/Paisley_Print_Babydoll_Dress/img_00000029.jpg             train\n",
       "289197  img/Paisley_Print_Babydoll_Dress/img_00000030.jpg             train\n",
       "289198  img/Paisley_Print_Babydoll_Dress/img_00000031.jpg             train\n",
       "289199  img/Paisley_Print_Babydoll_Dress/img_00000032.jpg             train\n",
       "289200  img/Paisley_Print_Babydoll_Dress/img_00000033.jpg             train\n",
       "289201  img/Paisley_Print_Babydoll_Dress/img_00000034.jpg             train\n",
       "289202  img/Paisley_Print_Babydoll_Dress/img_00000035.jpg             train\n",
       "289203  img/Paisley_Print_Babydoll_Dress/img_00000036.jpg               val\n",
       "289204  img/Paisley_Print_Babydoll_Dress/img_00000037.jpg             train\n",
       "289205  img/Paisley_Print_Babydoll_Dress/img_00000038.jpg             train\n",
       "289206  img/Paisley_Print_Babydoll_Dress/img_00000039.jpg             train\n",
       "289207  img/Paisley_Print_Babydoll_Dress/img_00000040.jpg               val\n",
       "289208  img/Paisley_Print_Babydoll_Dress/img_00000041.jpg               val\n",
       "289209  img/Paisley_Print_Babydoll_Dress/img_00000042.jpg             train\n",
       "289210  img/Paisley_Print_Babydoll_Dress/img_00000043.jpg               val\n",
       "289211  img/Paisley_Print_Babydoll_Dress/img_00000044.jpg              test\n",
       "289212  img/Paisley_Print_Babydoll_Dress/img_00000045.jpg             train\n",
       "289213  img/Paisley_Print_Babydoll_Dress/img_00000046.jpg             train\n",
       "289214  img/Paisley_Print_Babydoll_Dress/img_00000047.jpg             train\n",
       "289215  img/Paisley_Print_Babydoll_Dress/img_00000048.jpg             train\n",
       "289216  img/Paisley_Print_Babydoll_Dress/img_00000049.jpg              test\n",
       "289217  img/Paisley_Print_Babydoll_Dress/img_00000050.jpg             train\n",
       "289218  img/Paisley_Print_Babydoll_Dress/img_00000051.jpg             train\n",
       "289219  img/Paisley_Print_Babydoll_Dress/img_00000052.jpg             train\n",
       "289220  img/Paisley_Print_Babydoll_Dress/img_00000053.jpg             train\n",
       "289221  img/Paisley_Print_Babydoll_Dress/img_00000054.jpg               val\n",
       "\n",
       "[289222 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_table('list_eval_partition.txt', delim_whitespace=True)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_df = all_df[all_df['evaluation_status'].str.contains('val')]\n",
    "all_df = pd.read_table('list_eval_partition.txt', delim_whitespace=True)\n",
    "validation_df = all_df[all_df['evaluation_status'].str.contains('val')]\n",
    "validation_df = validation_df.drop(['evaluation_status'], axis=1)[0:100]\n",
    "\n",
    "train_df = all_df[all_df['evaluation_status'].str.contains('train')]\n",
    "train_df = train_df.drop(['evaluation_status'], axis=1)[0:100]\n",
    "\n",
    "test_df = all_df[all_df['evaluation_status'].str.contains('test')]\n",
    "test_df = test_df.drop(['evaluation_status'], axis=1)[0:100]\n",
    "\n",
    "labels_df = pd.read_table('list_category_img.txt', delim_whitespace=True)\n",
    "labels_df\n",
    "\n",
    "def func(imagee): \n",
    "    category_label = labels_df[labels_df['image_name'].str.match(imagee)].iloc[0]['category_label']\n",
    "    return category_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "allimagesvalidation = []\n",
    "labelvalidation = []\n",
    "for index in range(100):\n",
    "    img_filepath = validation_df.iloc[index]['image_name']\n",
    "    im = Image.open(img_filepath)\n",
    "    labelvalidation.append(func(img_filepath))\n",
    "    imarr = np.uint8(np.asarray(im.convert('RGB').resize((224,224))))\n",
    "    allimagesvalidation.append(imarr)\n",
    "\n",
    "allimagestrain = []\n",
    "labeltrain = []\n",
    "for index in range(100):\n",
    "    img_filepath = train_df.iloc[index]['image_name']\n",
    "    im = Image.open(img_filepath) # loads a JPEG image into Python \n",
    "    labeltrain.append(func(img_filepath))\n",
    "    imarr = np.uint8(np.asarray(im.convert('RGB').resize((224,224))))\n",
    "    allimagestrain.append(imarr)\n",
    "\n",
    "allimagestest = []\n",
    "labeltest = []\n",
    "for index in range(100):\n",
    "    img_filepath = test_df.iloc[index]['image_name']\n",
    "    im = Image.open(img_filepath)\n",
    "    labeltest.append(func(img_filepath))\n",
    "    imarr = np.uint8(np.asarray(im.convert('RGB').resize((224,224))))\n",
    "    allimagestest.append(imarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClothingDataset(Dataset):\n",
    "    def __init__(self, data, labels): \n",
    "        self.labels = labels\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        \n",
    "        trans = transforms.ToTensor()\n",
    "        img = trans(img)\n",
    "        \n",
    "        label = self.labels[index]\n",
    "        label = torch.LongTensor(label)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "train_dataset = ClothingDataset(allimagestrain, labeltrain)\n",
    "validation_dataset = ClothingDataset(allimagesvalidation, labelvalidation) \n",
    "test_dataset = ClothingDataset(allimagestest, labeltest)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,                                             \n",
    "                                           shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, \n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetModel(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(ConvolutionalNeuralNetModel, self).__init__()\n",
    "        # first number is depth (3 layers in pixels cuz rgb) and second is output dimensions\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=4, stride=2, padding=2, bias=False) # change \n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        self.fc = nn.Linear(50000, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28 * 28 \n",
    "hidden_dim = 100\n",
    "output_dim = 50 # represents number of labels you're trying to train on \n",
    "\n",
    "# model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
    "model = ConvolutionalNeuralNetModel(output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [10 x 51984], m2: [50000 x 50] at /Users/soumith/mc3build/conda-bld/pytorch_1549597882250/work/aten/src/TH/generic/THTensorMath.cpp:940",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-50aa2704e83a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Forward pass to get output/logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Calculate Loss: softmax --> cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-7264481828e7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [10 x 51984], m2: [50000 x 50] at /Users/soumith/mc3build/conda-bld/pytorch_1549597882250/work/aten/src/TH/generic/THTensorMath.cpp:940"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "losses = []\n",
    "accuracies = []\n",
    "for epoch in range(1):\n",
    "    #for i, (images, labels) in enumerate(train_loader):\n",
    "    for images, labels in train_loader:\n",
    "        # Load images with gradient accumulation capabilities\n",
    "        # images = images.view(-1, 28*28).requires_grad_()\n",
    "        # images = images.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 60 == 0: \n",
    "            # Calculate Accuracy \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images with gradient accumulation capabilities\n",
    "                # images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            accuracies.append(accuracy)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
