{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Rest of Semester (from Hao): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Hello all. Just a quick thing on the upcoming schedule. As 8 week projects we get an extra week (the week between 4 week project cycles) and we also get Spring Break. It will be up to you to decide whether you want to commit time to the project over spring break.\n",
    "\n",
    "Meeting this week will be in Moffit 511 the usual time.\n",
    "\n",
    "Here are our future meeting dates:\n",
    "Mar 21st Roadmap + Research\n",
    "Mar 28th No meeting (spring break)\n",
    "Apr  4th Model build checkpoint (training begins now)\n",
    "Apr 11th Ensembling (Model should be finished) (NLP people don't have to worry about Ensembling)\n",
    "Apr 18th deployment\n",
    "Apr 25th Recap\n",
    "\n",
    "This gives us 3 weeks to finish building the model. Keep in mind that this isn't something you do last minute. There will be many struggles as you try to figure out what layers go together and how. Then there will be struggles with data loading along with retuning the model. We are attempting to get strong model not a last minute model.\n",
    "\n",
    "Realistically you should be training/testing throughout the construction of your model to test its viability and correctness (lack of bugs). The phases of building and training are more fluid than what I've set on the schedule. They're actually cyclic (build->train->modify->train more->etc) until we're satisfied.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Thoughts Before Diving Into Coding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Link to setting up Jupyter notebook with PyTorch, Keras, & Tensorflow for deep learning: https://sharifuli.com/2018/02/16/tensorflow-keras-pytorch/\n",
    "\n",
    "Reference for Fasion Dataset info --> https://arxiv.org/abs/1708.07747\n",
    "Reference for model --> https://hackernoon.com/tf-serving-keras-mobilenetv2-632b8d92983c or https://www.pyimagesearch.com/2019/02/11/fashion-mnist-with-keras-and-deep-learning/ or https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5 or https://github.com/xuyuwei/resnet-tf\n",
    "My ideas after doing additional research into this Fashion dataset for image classification specifically: \n",
    "\n",
    "- The Fashion-MNIST dataset has 70,000 grayscale (28x28) pixel images (can interpret this as a big array of numbers and can flatten this array into a vector of 28x28 = 784 numbers) that are separated into the categories of Label & Description. Specifically, there are 10 categories and 7000 images per category. The training set has 60,000 images and the test set has 10,000 images...why? Because it makes sense to have your model better deveoped in the training stages and in order to cover all potential scenarios and special edge cases, your training set needs to be large. This is dataset is also already optimized and labeled for a classification problem. \n",
    "    - Note: When dealing with classifiation problem, you are dealing with logistic regression.\n",
    "    - Note: if flattening array, the result is that mnist.train.images is a tensor (an n-dimensional array) with a shape of [70000, 784]. The first dimension is an index into the list of images and the second dimension is the index for each pixel in each image. Each entry in the tensor is a pixel intensity between 0 and 1, for a particular pixel in a particular image.\n",
    "    \n",
    "\n",
    "- Stages of Preparing My Data for Training: \n",
    "    - Identify Bias\n",
    "    - Remove outliers from data (eg. can take care by replacing a value by the mean of all the values collectively in that same column)\n",
    "    - Transform dataset so that all are represented as numbers\n",
    "        - apply encoding (one-hot, binary, 0s and 1s, etc.) to categorical features to convert to integers \n",
    "            - example is to convert labels (y_train and y_test) to one-hot encoding, which is a representation of categorical variables as binary vectors \n",
    "        - split into train and test set (can use load_data() function)\n",
    "        - after training NN, run the trained model against validation dataset to make sure model is not generalized and does not have the problem of overfitting (when a model predicts the right result when it tests against training data, but otherwise fails to predict accurately.) \n",
    "        - last stage is to run model against test dataset (the last dataset to be used)\n",
    "        - data normalization might be needed\n",
    "            - adjust dimensions of data so that they are on same scale, esp because we are dealing with pixels within images here \n",
    "            - normalization makes NN faster esp in case of Convolutional or Recurrent NN\n",
    "        - resize images & convert to 3 channels of the primary colors (RGB) \n",
    "            - to do this: use Python Generator built-in function \n",
    "            \n",
    "- Training Deep Learning Model: \n",
    "    - Note that \"transfer learning\" is huge in deep learning, because a lot of times, the models that you end up using already come pre-trained or with a similar dataset\n",
    "        - Which model to use? \n",
    "            - in this case, makes sense to use \"MobileNet V2\" model b/c it's faster to train and small in size AND also is pre-trained with ImageNet dataset (Fashion data is a subset of this larger set) \n",
    "            - HOWEVER, I will start off with employing a (vanilla) ANN model just to get practice, and then will also try to improve this by building a DNN with 2 hidden layers from scratch! \n",
    "            - can also mess around with a CNN https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/ and http://cs231n.github.io/convolutional-networks/?fbclid=IwAR2-VAvy2UgPZnToLdbonMaOS4Dp0931uaDywGzecVK6PXktWk660P-odW4\n",
    "        - activation function I can try: \"ReLu\" --> gives an output x if x is positive and 0 if otherwise (ReLu is nonlinear in nature which means it's less dense because fewer neurons are firing so this allows for sparse activation & is thus less computationally expensive than tanh or sigmoid functions)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Confusions I Have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I still am lost on wheret the Paper Space machine comes into play \n",
    "- I am also still stuck on formulating a solid business problem, i.e., what exactly am I trying to solve here? I feel like I am just getting practice trying to write code for preparing the same Fashion dataset and deciding which model to apply, etc. so is that the point of this project? Are we all doing this and the difference depends on what model we use? \n",
    "- How does this fit into what the image classification team has to do? I think I'm just getting very confused because there are so many concepts in this domain that I am unsure of what direction I should head in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding using Tensorflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Model Attempt: (Vanilla) ANN Network\n",
    "- Any Neural Network with one hidden layer can be a Universal Function Approximator. Source: https://en.wikipedia.org/wiki/Universal_approximation_theorem\n",
    "- The number of input nodes are equal to the number of features\n",
    "- The number of output nodes are equal to the number of classes (for classification tasks)\n",
    "- A bias term is added to every layer that only feeds in a 1, that adds an extra degree of freedom for every functional input value to the next function\n",
    "- We don't make use of the image shapes and curves. Shape info is lost when we flatten arrays. (I'm just doing this to try it out and get some practice)\n",
    "- What I will accomplish in this section:\n",
    "    - Create a softmax regression function that is a model for recognizing MNIST images, based on looking at every pixel in the image\n",
    "    - Use Tensorflow to train the model to recognize images by having it \"look\" at thousands of examples (and run our first Tensorflow session to do so)\n",
    "    - Check the model's accuracy with our test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion Data Info: \n",
    "- Similar to the MNIST digit dataset, the Fashion MNIST dataset includes:\n",
    "    - 60,000 training examples\n",
    "    - 10,000 testing examples\n",
    "    - 10 classes\n",
    "    - 28Ã—28 grayscale/single channel images\n",
    "- The ten fashion class labels include:\n",
    "    - T-shirt/top\n",
    "    - Trouser/pants\n",
    "    - Pullover shirt\n",
    "    - Dress\n",
    "    - Coat\n",
    "    - Sandal\n",
    "    - Shirt\n",
    "    - Sneaker\n",
    "    - Bag\n",
    "    - Ankle boot   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
